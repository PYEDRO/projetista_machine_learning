{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MYNes3QZRlo"
      },
      "source": [
        "## Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNf0NSmJZLAt"
      },
      "outputs": [],
      "source": [
        "!pip -q install timm kaggle scikit-learn\n",
        "\n",
        "import os, random, time\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import timm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2brQGhpFZX-b"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPBbVPmvue46",
        "outputId": "136b93ed-0af4-426a-d3a9-a9fae930efaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-EnkMNJnZaYq",
        "outputId": "9cd3aa7e-111a-41ad-9e1d-a46d7aa22a57"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@dataclass\n",
        "class CFG:\n",
        "    data_root: str = \"/content/drive/MyDrive/archive (1)\"\n",
        "    seed: int = 42\n",
        "\n",
        "    img_size: int = 224\n",
        "    batch_size: int = 32\n",
        "\n",
        "    model_name: str = \"tf_efficientnetv2_s\"\n",
        "\n",
        "    lr_head: float = 5e-4\n",
        "    lr_full: float = 1e-4\n",
        "    weight_decay: float = 1e-4\n",
        "\n",
        "    epochs_head: int = 5\n",
        "    epochs_full: int = 15\n",
        "    patience: int = 4\n",
        "\n",
        "    max_other: int = 200\n",
        "\n",
        "    use_mixup: bool = True\n",
        "    mixup_alpha: float = 0.2\n",
        "\n",
        "    focal_gamma: float = 2.0\n",
        "\n",
        "    # threshold search\n",
        "    thr_min: float = 0.20\n",
        "    thr_max: float = 0.90\n",
        "    thr_steps: int = 29\n",
        "\n",
        "cfg = CFG()\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "set_seed(cfg.seed)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85WPEpMiinOI"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbfrQQUzipa-",
        "outputId": "97e5f234-8084-4130-f6db-5d854f28c30a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([PosixPath('/content/drive/MyDrive/archive (1)/train')], 1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "root = Path(cfg.data_root)\n",
        "candidates = list(root.rglob(\"data\"))\n",
        "candidates[:5], len(candidates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNPNSwKcivJp",
        "outputId": "abd86873-cce5-4261-8210-a9887e77bc9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(PosixPath('/content/drive/MyDrive/archive (1)/train'),\n",
              " PosixPath('/content/drive/MyDrive/archive (1)/test'),\n",
              " True,\n",
              " True)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dir = candidates[0]\n",
        "test_dir = train_dir.parent / \"test\"\n",
        "train_dir, test_dir, train_dir.exists(), test_dir.exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja6xMgRTi0ts"
      },
      "source": [
        "## Construct Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCqvfAqJu0TG",
        "outputId": "6c55c6cb-b889-431d-ce18-59a9436116eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Aviso: não encontrei 'BMW 7 Series Sedan 2012' neste dataset.\n",
            "Isso é esperado no Stanford Cars original.\n",
            "Vou usar fallback no lugar da Série 7: 'BMW X5 SUV 2007'\n",
            "\n",
            "✅ Targets fixas escolhidas:\n",
            "Classe 3: BMW 3 Series Sedan 2012\n",
            "Classe 5: BMW ActiveHybrid 5 Sedan 2012 (choice=ActiveHybrid 5)\n",
            "Classe 7: BMW X5 SUV 2007 (fallback)\n",
            "Other BMW classes: 10\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tmp_base = datasets.ImageFolder(train_dir, transform=transforms.ToTensor())\n",
        "all_classes = tmp_base.classes\n",
        "\n",
        "BMW_3 = \"BMW 3 Series Sedan 2012\"\n",
        "\n",
        "BMW_5_OPTION_1 = \"BMW ActiveHybrid 5 Sedan 2012\"\n",
        "BMW_5_OPTION_2 = \"BMW M5 Sedan 2010\"\n",
        "\n",
        "BMW_7 = \"BMW 7 Series Sedan 2012\"\n",
        "\n",
        "def must_exist(name):\n",
        "    return name in all_classes\n",
        "\n",
        "if not must_exist(BMW_3):\n",
        "    raise RuntimeError(\n",
        "        f\"Não encontrei a pasta '{BMW_3}'. \"\n",
        "        f\"Confira o dataset/pastas. Exemplo de classes BMW disponíveis: \"\n",
        "        f\"{[c for c in all_classes if 'BMW' in c.upper()][:10]}\"\n",
        "    )\n",
        "\n",
        "if must_exist(BMW_5_OPTION_1):\n",
        "    BMW_5 = BMW_5_OPTION_1\n",
        "    BMW_5_CHOICE = \"ActiveHybrid 5\"\n",
        "elif must_exist(BMW_5_OPTION_2):\n",
        "    BMW_5 = BMW_5_OPTION_2\n",
        "    BMW_5_CHOICE = \"M5\"\n",
        "else:\n",
        "    raise RuntimeError(\n",
        "        f\"Não encontrei nem '{BMW_5_OPTION_1}' nem '{BMW_5_OPTION_2}'. \"\n",
        "        f\"Classes BMW disponíveis: {[c for c in all_classes if 'BMW' in c.upper()]}\"\n",
        "    )\n",
        "\n",
        "bmw7_exists = must_exist(BMW_7)\n",
        "if not bmw7_exists:\n",
        "    fallback_candidates = [\n",
        "        \"BMW X5 SUV 2007\",\n",
        "        \"BMW X6 SUV 2012\",\n",
        "        \"BMW Z4 Convertible 2012\",\n",
        "        \"BMW M3 Coupe 2012\",\n",
        "        \"BMW 3 Series Wagon 2012\",\n",
        "    ]\n",
        "    fallback = next((c for c in fallback_candidates if must_exist(c)), None)\n",
        "\n",
        "    msg = (\n",
        "        f\"Aviso: não encontrei '{BMW_7}' neste dataset.\\n\"\n",
        "        f\"Isso é esperado no Stanford Cars original.\\n\"\n",
        "    )\n",
        "    if fallback is None:\n",
        "        msg += \"Também não achei um fallback padrão. Listei as BMW disponíveis abaixo.\\n\"\n",
        "        print(msg)\n",
        "        print(\"BMW disponíveis:\", [c for c in all_classes if \"BMW\" in c.upper()])\n",
        "        raise RuntimeError(\"Sem classe para Série 7 e sem fallback disponível.\")\n",
        "    else:\n",
        "        msg += f\"Vou usar fallback no lugar da Série 7: '{fallback}'\\n\"\n",
        "        print(msg)\n",
        "        BMW_7 = fallback\n",
        "\n",
        "targets = [BMW_3, BMW_5, BMW_7]\n",
        "\n",
        "print(\"Targets fixas escolhidas:\")\n",
        "print(\"Classe 3:\", BMW_3)\n",
        "print(\"Classe 5:\", BMW_5, f\"(choice={BMW_5_CHOICE})\")\n",
        "print(\"Classe 7:\", BMW_7, \"(7 original)\" if bmw7_exists else \"(fallback)\")\n",
        "\n",
        "bmw_classes = [c for c in all_classes if \"BMW\" in c.upper()]\n",
        "other_bmw = [c for c in bmw_classes if c not in targets]\n",
        "print(\"Other BMW classes:\", len(other_bmw))\n",
        "\n",
        "label_map = {targets[0]: 0, targets[1]: 1, targets[2]: 2, \"OTHER\": 3}\n",
        "\n",
        "idx_to_name = {0:\"BMW_3Series\", 1:\"BMW_5Series\", 2:\"BMW_7Series_or_Fallback\", 3:\"undefined\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwqOFssjIVu"
      },
      "source": [
        "## Dataset custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r96ZjnKjLbV"
      },
      "outputs": [],
      "source": [
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(cfg.img_size, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tfms = transforms.Compose([\n",
        "    transforms.Resize(int(cfg.img_size*1.14)),\n",
        "    transforms.CenterCrop(cfg.img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "base = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
        "class_to_idx = base.class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z8hNLMgsds8",
        "outputId": "d571a889-c5cb-45b8-bbb4-4e60270a7908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuição antes do split:\n",
            "BMW_3Series 43\n",
            "BMW_5Series 34\n",
            "BMW_7Series_or_Fallback 42\n",
            "undefined 200\n",
            "Sanity labels unique: tensor([0, 1, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "class MappedSubset(Dataset):\n",
        "    def __init__(self, base_ds, indices, new_labels):\n",
        "        assert len(indices) == len(new_labels)\n",
        "        self.base_ds = base_ds\n",
        "        self.indices = list(indices)\n",
        "        self.new_labels = np.array(new_labels, dtype=np.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        x, _ = self.base_ds[self.indices[i]]\n",
        "        return x, int(self.new_labels[i])\n",
        "\n",
        "base_train = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
        "base_val   = datasets.ImageFolder(train_dir, transform=test_tfms)\n",
        "\n",
        "target_set = set(targets)\n",
        "other_set  = set(other_bmw)\n",
        "\n",
        "target_indices, target_labels = [], []\n",
        "other_indices = []\n",
        "\n",
        "for i, (path, y_old) in enumerate(base_train.samples):\n",
        "    cls_name = base_train.classes[y_old]\n",
        "    if cls_name in target_set:\n",
        "        target_indices.append(i)\n",
        "        target_labels.append(label_map[cls_name])\n",
        "    elif cls_name in other_set:\n",
        "        other_indices.append(i)\n",
        "\n",
        "np.random.shuffle(other_indices)\n",
        "MAX_OTHER = getattr(cfg, \"max_other\", 200)\n",
        "other_indices = other_indices[:MAX_OTHER]\n",
        "other_labels = [label_map[\"OTHER\"]] * len(other_indices)\n",
        "\n",
        "sel_idx = np.array(target_indices + other_indices)\n",
        "sel_y   = np.array(target_labels + other_labels, dtype=np.int64)\n",
        "\n",
        "print(\"Distribuição antes do split:\")\n",
        "unique, counts = np.unique(sel_y, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(idx_to_name[int(u)], c)\n",
        "\n",
        "train_pos, val_pos = train_test_split(\n",
        "    np.arange(len(sel_idx)),\n",
        "    test_size=0.30,\n",
        "    random_state=cfg.seed,\n",
        "    stratify=sel_y\n",
        ")\n",
        "\n",
        "train_ds = MappedSubset(base_train, sel_idx[train_pos], sel_y[train_pos])\n",
        "val_ds   = MappedSubset(base_val,   sel_idx[val_pos],   sel_y[val_pos])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=0, pin_memory=False, drop_last=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=0, pin_memory=False)\n",
        "\n",
        "xb, yb = next(iter(train_loader))\n",
        "print(\"Sanity labels unique:\", torch.unique(yb))\n",
        "assert yb.min() >= 0 and yb.max() <= 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZPQEEI4jQJG"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "4d10b956675344dfb576d266e754f6c9",
            "962bbb76a03d480b851c5135b41780e7",
            "62dc982ac5e744ea8e1f314476156ece",
            "e3b3670bb85945babcbfe5efbc27debb",
            "9d3193117c1a43d98010cfecebd23592",
            "336a356efbf3407cbefd99faf8cf5cb6",
            "b871592528824d81b97473e1bddaffb9",
            "7de382acc7654fb29b09804ef193e5b2",
            "8238ccb2f6544da29b6f4dc3e0fd3042",
            "22d79a7fc74f455f805fccda260a3940",
            "7470e3b52eef45f0a4ea5506a92e3461"
          ]
        },
        "id": "fqFHROUSlOd6",
        "outputId": "effbd5f9-d4f0-4e88-d531-2b539362217c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d10b956675344dfb576d266e754f6c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/86.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = timm.create_model(cfg.model_name, pretrained=True, num_classes=4).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDtCpfRU0fJn"
      },
      "outputs": [],
      "source": [
        "train_labels_all = sel_y[train_pos]\n",
        "weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.array([0,1,2,3]),\n",
        "    y=train_labels_all\n",
        ")\n",
        "weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.05)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCeN_2QO7hSC"
      },
      "source": [
        "## Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJfuXVQX7jfG"
      },
      "outputs": [],
      "source": [
        "train_labels_all = sel_y[train_pos]\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.array([0,1,2,3]),\n",
        "    y=train_labels_all\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "\n",
        "class FocalLossMulti(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss para multi-classe:\n",
        "    - suporta targets hard (shape [B]) ou soft (shape [B, C]) (ex.: mixup).\n",
        "    - suporta class weights (shape [C]).\n",
        "    \"\"\"\n",
        "    def __init__(self, gamma=2.0, weight=None, eps=1e-7):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.register_buffer(\"weight\", weight if weight is not None else None)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        log_probs = torch.log_softmax(logits, dim=1)\n",
        "        probs = torch.exp(log_probs)\n",
        "\n",
        "        if targets.dim() == 1:\n",
        "            targets_oh = torch.zeros_like(logits).scatter_(1, targets.unsqueeze(1), 1.0)\n",
        "        else:\n",
        "            targets_oh = targets\n",
        "\n",
        "        pt = (probs * targets_oh).sum(dim=1).clamp(min=self.eps, max=1.0)\n",
        "\n",
        "        ce = -(targets_oh * log_probs).sum(dim=1)\n",
        "\n",
        "        if self.weight is not None:\n",
        "            w = (targets_oh * self.weight.unsqueeze(0)).sum(dim=1)\n",
        "            ce = ce * w\n",
        "\n",
        "        loss = ((1.0 - pt) ** self.gamma) * ce\n",
        "        return loss.mean()\n",
        "\n",
        "FOCAL_GAMMA = getattr(cfg, \"focal_gamma\", 2.0)\n",
        "criterion = FocalLossMulti(gamma=FOCAL_GAMMA, weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDFmkbF10jz6"
      },
      "outputs": [],
      "source": [
        "mixup_fn = None\n",
        "\n",
        "USE_MIXUP = getattr(cfg, \"use_mixup\", True)\n",
        "MIXUP_A   = getattr(cfg, \"mixup_alpha\", 0.2)\n",
        "\n",
        "if USE_MIXUP:\n",
        "    from timm.data import Mixup\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=MIXUP_A,\n",
        "        cutmix_alpha=0.0,\n",
        "        label_smoothing=0.0,\n",
        "        num_classes=4\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weWHYD5djXgW"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r22AupQjXHp",
        "outputId": "33c51dd9-b726-4e3b-b500-15bae81041a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n"
          ]
        }
      ],
      "source": [
        "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "\n",
        "def run_epoch(model, loader, train=True):\n",
        "    \"\"\"\n",
        "    Assinatura fixa:\n",
        "      - se train=False, passe optimizer=None\n",
        "    \"\"\"\n",
        "    model.train(train)\n",
        "    losses = []\n",
        "    all_probs = []\n",
        "    all_targets = []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        if train and mixup_fn is not None:\n",
        "            x, y_mix = mixup_fn(x, y)  \n",
        "        else:\n",
        "            y_mix = y  \n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y_mix)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        probs = torch.softmax(logits.detach(), dim=1).cpu().numpy()\n",
        "        all_probs.append(probs)\n",
        "        all_targets.append(y.detach().cpu().numpy())\n",
        "\n",
        "    all_probs = np.concatenate(all_probs, axis=0)\n",
        "    all_targets = np.concatenate(all_targets, axis=0)\n",
        "    preds = all_probs.argmax(axis=1)\n",
        "\n",
        "    acc = accuracy_score(all_targets, preds)\n",
        "    f1  = f1_score(all_targets, preds, average=\"macro\")\n",
        "    return float(np.mean(losses)), acc, f1\n",
        "\n",
        "\n",
        "def freeze_backbone(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in model.get_classifier().parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def unfreeze_all(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def run_epoch2(model, loader, criterion, optimizer, train: bool):\n",
        "    \"\"\"\n",
        "    Assinatura fixa:\n",
        "      - se train=False, passe optimizer=None\n",
        "    \"\"\"\n",
        "    model.train(train)\n",
        "    losses = []\n",
        "    all_probs = []\n",
        "    all_targets = []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        if train and mixup_fn is not None:\n",
        "            x, y_mix = mixup_fn(x, y)  \n",
        "        else:\n",
        "            y_mix = y  \n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y_mix)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        probs = torch.softmax(logits.detach(), dim=1).cpu().numpy()\n",
        "        all_probs.append(probs)\n",
        "        all_targets.append(y.detach().cpu().numpy())\n",
        "\n",
        "    all_probs = np.concatenate(all_probs, axis=0)\n",
        "    all_targets = np.concatenate(all_targets, axis=0)\n",
        "    preds = all_probs.argmax(axis=1)\n",
        "\n",
        "    acc = accuracy_score(all_targets, preds)\n",
        "    f1  = f1_score(all_targets, preds, average=\"macro\")\n",
        "    return float(np.mean(losses)), acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzuHDWg1HqCo",
        "outputId": "6fa42f26-6047-472d-b3e8-774482acb4b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 01 | lr=5.0e-05 wd=1.0e-05 gamma=1.5 -> macroF1=0.283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 02 | lr=5.0e-05 wd=1.0e-05 gamma=2.0 -> macroF1=0.328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 03 | lr=5.0e-05 wd=1.0e-05 gamma=2.5 -> macroF1=0.389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 04 | lr=5.0e-05 wd=1.0e-04 gamma=1.5 -> macroF1=0.264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 05 | lr=5.0e-05 wd=1.0e-04 gamma=2.0 -> macroF1=0.362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 06 | lr=5.0e-05 wd=1.0e-04 gamma=2.5 -> macroF1=0.297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 07 | lr=5.0e-05 wd=5.0e-04 gamma=1.5 -> macroF1=0.367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 08 | lr=5.0e-05 wd=5.0e-04 gamma=2.0 -> macroF1=0.380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 09 | lr=5.0e-05 wd=5.0e-04 gamma=2.5 -> macroF1=0.420\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 10 | lr=1.0e-04 wd=1.0e-05 gamma=1.5 -> macroF1=0.424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 11 | lr=1.0e-04 wd=1.0e-05 gamma=2.0 -> macroF1=0.454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 12 | lr=1.0e-04 wd=1.0e-05 gamma=2.5 -> macroF1=0.397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 13 | lr=1.0e-04 wd=1.0e-04 gamma=1.5 -> macroF1=0.478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 14 | lr=1.0e-04 wd=1.0e-04 gamma=2.0 -> macroF1=0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 15 | lr=1.0e-04 wd=1.0e-04 gamma=2.5 -> macroF1=0.419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 16 | lr=1.0e-04 wd=5.0e-04 gamma=1.5 -> macroF1=0.376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 17 | lr=1.0e-04 wd=5.0e-04 gamma=2.0 -> macroF1=0.490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 18 | lr=1.0e-04 wd=5.0e-04 gamma=2.5 -> macroF1=0.350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 19 | lr=2.0e-04 wd=1.0e-05 gamma=1.5 -> macroF1=0.498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 20 | lr=2.0e-04 wd=1.0e-05 gamma=2.0 -> macroF1=0.475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 21 | lr=2.0e-04 wd=1.0e-05 gamma=2.5 -> macroF1=0.502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 22 | lr=2.0e-04 wd=1.0e-04 gamma=1.5 -> macroF1=0.520\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 23 | lr=2.0e-04 wd=1.0e-04 gamma=2.0 -> macroF1=0.571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 24 | lr=2.0e-04 wd=1.0e-04 gamma=2.5 -> macroF1=0.618\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 25 | lr=2.0e-04 wd=5.0e-04 gamma=1.5 -> macroF1=0.651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 26 | lr=2.0e-04 wd=5.0e-04 gamma=2.0 -> macroF1=0.462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trial 27 | lr=2.0e-04 wd=5.0e-04 gamma=2.5 -> macroF1=0.521\n",
            "\n",
            "TOP-5:\n",
            "{'trial': 25, 'lr_full': 0.0002, 'weight_decay': 0.0005, 'focal_gamma': 1.5, 'macro_f1': 0.6512445887445887}\n",
            "{'trial': 24, 'lr_full': 0.0002, 'weight_decay': 0.0001, 'focal_gamma': 2.5, 'macro_f1': 0.6179246635962827}\n",
            "{'trial': 23, 'lr_full': 0.0002, 'weight_decay': 0.0001, 'focal_gamma': 2.0, 'macro_f1': 0.5712438423645321}\n",
            "{'trial': 27, 'lr_full': 0.0002, 'weight_decay': 0.0005, 'focal_gamma': 2.5, 'macro_f1': 0.5212923500796418}\n",
            "{'trial': 22, 'lr_full': 0.0002, 'weight_decay': 0.0001, 'focal_gamma': 1.5, 'macro_f1': 0.5199967083607637}\n",
            "\n",
            "✅ Selected hparams:\n",
            "lr_full     = 0.0002\n",
            "weight_decay= 0.0005\n",
            "focal_gamma = 1.5\n"
          ]
        }
      ],
      "source": [
        "def train_eval_short(model_name, lr_full, weight_decay, focal_gamma,\n",
        "                     epochs_head=2, epochs_full=4, patience=2):\n",
        "    model = timm.create_model(model_name, pretrained=True, num_classes=4).to(device)\n",
        "\n",
        "    criterion = FocalLossMulti(gamma=focal_gamma, weight=class_weights)\n",
        "\n",
        "    freeze_backbone(model)\n",
        "    opt = torch.optim.AdamW(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=getattr(cfg, \"lr_head\", 5e-4),\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    best = -1\n",
        "    bad = 0\n",
        "    for _ in range(max(1, epochs_head)):\n",
        "        _ = run_epoch2(model, train_loader, criterion, optimizer=opt, train=True)\n",
        "        _, _, f1v = run_epoch2(model, val_loader, criterion, optimizer=None, train=False)\n",
        "        if f1v > best:\n",
        "            best = f1v; bad = 0\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                break\n",
        "\n",
        "    unfreeze_all(model)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr_full, weight_decay=weight_decay)\n",
        "\n",
        "    best = -1\n",
        "    bad = 0\n",
        "    for _ in range(max(1, epochs_full)):\n",
        "        _ = run_epoch2(model, train_loader, criterion, optimizer=opt, train=True)\n",
        "        _, _, f1v = run_epoch2(model, val_loader, criterion, optimizer=None, train=False)\n",
        "        if f1v > best:\n",
        "            best = f1v; bad = 0\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                break\n",
        "\n",
        "    return best\n",
        "\n",
        "\n",
        "if getattr(cfg, \"do_hparam_search\", True):\n",
        "    search_space = {\n",
        "        \"lr_full\":      [5e-5, 1e-4, 2e-4],\n",
        "        \"weight_decay\": [1e-5, 1e-4, 5e-4],\n",
        "        \"focal_gamma\":  [1.5, 2.0, 2.5],\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    trial = 0\n",
        "\n",
        "    for lr in search_space[\"lr_full\"]:\n",
        "        for wd in search_space[\"weight_decay\"]:\n",
        "            for g in search_space[\"focal_gamma\"]:\n",
        "                trial += 1\n",
        "                f1v = train_eval_short(\n",
        "                    model_name=cfg.model_name,\n",
        "                    lr_full=lr,\n",
        "                    weight_decay=wd,\n",
        "                    focal_gamma=g,\n",
        "                    epochs_head=getattr(cfg, \"hs_epochs_head\", 2),\n",
        "                    epochs_full=getattr(cfg, \"hs_epochs_full\", 4),\n",
        "                    patience=getattr(cfg, \"hs_patience\", 2)\n",
        "                )\n",
        "                results.append({\"trial\": trial, \"lr_full\": lr, \"weight_decay\": wd, \"focal_gamma\": g, \"macro_f1\": f1v})\n",
        "                print(f\"trial {trial:02d} | lr={lr:.1e} wd={wd:.1e} gamma={g:.1f} -> macroF1={f1v:.3f}\")\n",
        "\n",
        "    results_sorted = sorted(results, key=lambda x: x[\"macro_f1\"], reverse=True)\n",
        "    best = results_sorted[0]\n",
        "    print(\"\\nTOP-5:\")\n",
        "    for r in results_sorted[:5]:\n",
        "        print(r)\n",
        "\n",
        "    cfg.lr_full = best[\"lr_full\"]\n",
        "    cfg.weight_decay = best[\"weight_decay\"]\n",
        "    cfg.focal_gamma = best[\"focal_gamma\"]\n",
        "\n",
        "    print(\"\\n Selected hparams:\")\n",
        "    print(\"lr_full     =\", cfg.lr_full)\n",
        "    print(\"weight_decay=\", cfg.weight_decay)\n",
        "    print(\"focal_gamma =\", cfg.focal_gamma)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1nXTCoP8jtq"
      },
      "source": [
        "## Fine Turning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqDWqduM03w3",
        "outputId": "8652f25b-1794-43a0-99c8-632a14462aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Final Phase 1: Head training (freeze) ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Head] Epoch 01 | train f1 0.151 | val f1 0.108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Head] Epoch 02 | train f1 0.178 | val f1 0.085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Head] Epoch 03 | train f1 0.225 | val f1 0.113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Head] Epoch 04 | train f1 0.236 | val f1 0.173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Head] Epoch 05 | train f1 0.277 | val f1 0.174\n",
            "\n",
            "=== Final Phase 2: Full fine-tuning (unfreeze) ===\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 01 | train f1 0.220 | val f1 0.309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 02 | train f1 0.408 | val f1 0.410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 03 | train f1 0.331 | val f1 0.479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 04 | train f1 0.522 | val f1 0.554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 05 | train f1 0.600 | val f1 0.581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 06 | train f1 0.650 | val f1 0.571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 07 | train f1 0.626 | val f1 0.550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 08 | train f1 0.451 | val f1 0.551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
            "/tmp/ipython-input-3841390307.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Full] Epoch 09 | train f1 0.526 | val f1 0.556\n",
            "Early stopping (full).\n",
            "\n",
            "Best val macro-F1: 0.5813156906906907\n"
          ]
        }
      ],
      "source": [
        "model = timm.create_model(cfg.model_name, pretrained=True, num_classes=4).to(device)\n",
        "\n",
        "criterion = FocalLossMulti(gamma=getattr(cfg, \"focal_gamma\", 2.0), weight=class_weights)\n",
        "\n",
        "EPOCHS_HEAD = getattr(cfg, \"epochs_head\", 5)\n",
        "EPOCHS_FULL = getattr(cfg, \"epochs_full\", 15)\n",
        "LR_HEAD     = getattr(cfg, \"lr_head\", 5e-4)\n",
        "LR_FULL     = getattr(cfg, \"lr_full\", 1e-4)\n",
        "WD          = getattr(cfg, \"weight_decay\", 1e-4)\n",
        "PATIENCE    = getattr(cfg, \"patience\", 4)\n",
        "\n",
        "best_f1 = -1\n",
        "pat = 0\n",
        "best_path = \"/content/best.pt\"\n",
        "\n",
        "freeze_backbone(model)\n",
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_HEAD, weight_decay=WD)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(1, EPOCHS_HEAD))\n",
        "\n",
        "print(\"\\n=== Final Phase 1: Head training (freeze) ===\")\n",
        "for epoch in range(EPOCHS_HEAD):\n",
        "    tr_loss, tr_acc, tr_f1 = run_epoch2(model, train_loader, criterion, optimizer, train=True)\n",
        "    va_loss, va_acc, va_f1 = run_epoch2(model, val_loader, criterion, None, train=False)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"[Head] Epoch {epoch+1:02d} | train f1 {tr_f1:.3f} | val f1 {va_f1:.3f}\")\n",
        "\n",
        "    if va_f1 > best_f1:\n",
        "        best_f1 = va_f1\n",
        "        pat = 0\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "    else:\n",
        "        pat += 1\n",
        "        if pat >= PATIENCE:\n",
        "            print(\"Early stopping (head).\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "unfreeze_all(model)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR_FULL, weight_decay=WD)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(1, EPOCHS_FULL))\n",
        "pat = 0\n",
        "\n",
        "print(\"\\n=== Final Phase 2: Full fine-tuning (unfreeze) ===\")\n",
        "for epoch in range(EPOCHS_FULL):\n",
        "    tr_loss, tr_acc, tr_f1 = run_epoch2(model, train_loader, criterion, optimizer=optimizer, train=True)\n",
        "    va_loss, va_acc, va_f1 = run_epoch2(model, val_loader, criterion, optimizer=None, train=False)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"[Full] Epoch {epoch+1:02d} | train f1 {tr_f1:.3f} | val f1 {va_f1:.3f}\")\n",
        "\n",
        "    if va_f1 > best_f1:\n",
        "        best_f1 = va_f1\n",
        "        pat = 0\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "    else:\n",
        "        pat += 1\n",
        "        if pat >= PATIENCE:\n",
        "            print(\"Early stopping (full).\")\n",
        "            break\n",
        "\n",
        "print(\"\\nBest val macro-F1:\", best_f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abe776iEw2GN"
      },
      "source": [
        "## Evaluat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kQmUvTVT3T8P",
        "outputId": "cdb4ffc8-d3f0-42b5-cc0d-f396265fc12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.1/689.1 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.3/159.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install onnx onnxruntime onnxscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERzH_wmWwwUg",
        "outputId": "6b29b3e5-0ffc-407a-a97c-82ec5d3b2a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sem rejeição:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "            BMW_3Series       0.42      0.77      0.54        13\n",
            "            BMW_5Series       0.62      0.50      0.56        10\n",
            "BMW_7Series_or_Fallback       0.47      0.69      0.56        13\n",
            "              undefined       0.78      0.58      0.67        60\n",
            "\n",
            "               accuracy                           0.61        96\n",
            "              macro avg       0.57      0.64      0.58        96\n",
            "           weighted avg       0.67      0.61      0.62        96\n",
            "\n",
            "\n",
            "Best threshold (macro-F1): 0.775 | macro-F1: 0.616\n",
            "\n",
            "Com rejeição (auto threshold): 0.7749999999999999\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "            BMW_3Series       0.48      0.77      0.59        13\n",
            "            BMW_5Series       0.62      0.50      0.56        10\n",
            "BMW_7Series_or_Fallback       0.57      0.62      0.59        13\n",
            "              undefined       0.77      0.68      0.73        60\n",
            "\n",
            "               accuracy                           0.67        96\n",
            "              macro avg       0.61      0.64      0.62        96\n",
            "           weighted avg       0.69      0.67      0.67        96\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2579829551.py:48: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W0217 18:30:20.699000 1657 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
            "W0217 18:30:21.831000 1657 torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'input' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0, sampling_ratio: 'int' = -1, aligned: 'bool' = False). Treating as an Input.\n",
            "W0217 18:30:21.833000 1657 torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'boxes' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0, sampling_ratio: 'int' = -1, aligned: 'bool' = False). Treating as an Input.\n",
            "W0217 18:30:21.834000 1657 torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'input' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0). Treating as an Input.\n",
            "W0217 18:30:21.837000 1657 torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'boxes' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0). Treating as an Input.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Obtain model graph for `EfficientNet([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `EfficientNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n",
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.onnx] Translate the graph into ONNX... ✅\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 17 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 120, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 115, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/BaseConverter.h:65: adapter_lookup: Assertion `false` failed: No Adapter To Version $17 for Pad\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied 225 of general pattern rewrite rules.\n",
            "\n",
            "ONNX exportado: /content/car_classifier.onnx\n",
            "Latency médio: 19.09 ms | device=cuda | batch=1 | iters=100\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "def predict_probs(model, loader):\n",
        "    model.eval()\n",
        "    probs_all, y_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "            probs_all.append(probs)\n",
        "            y_all.append(y.numpy())\n",
        "    return np.concatenate(probs_all, axis=0), np.concatenate(y_all, axis=0)\n",
        "\n",
        "va_probs, va_targets = predict_probs(model, val_loader)\n",
        "\n",
        "print(\"\\nSem rejeição:\")\n",
        "pred = va_probs.argmax(axis=1)\n",
        "print(classification_report(va_targets, pred, target_names=[idx_to_name[i] for i in range(4)]))\n",
        "\n",
        "def predict_with_rejection(probs, thr):\n",
        "    conf = probs.max(axis=1)\n",
        "    pred = probs.argmax(axis=1)\n",
        "    pred_rej = pred.copy()\n",
        "    pred_rej[conf < thr] = 3\n",
        "    return pred, pred_rej, conf\n",
        "\n",
        "ths = np.linspace(getattr(cfg,\"thr_min\",0.2), getattr(cfg,\"thr_max\",0.9), getattr(cfg,\"thr_steps\",29))\n",
        "best_t, best_macro = None, -1\n",
        "for t in ths:\n",
        "    _, pr, _ = predict_with_rejection(va_probs, t)\n",
        "    m = f1_score(va_targets, pr, average=\"macro\")\n",
        "    if m > best_macro:\n",
        "        best_macro = m\n",
        "        best_t = float(t)\n",
        "\n",
        "print(f\"\\nBest threshold (macro-F1): {best_t:.3f} | macro-F1: {best_macro:.3f}\")\n",
        "\n",
        "_, pred_rej, _ = predict_with_rejection(va_probs, best_t)\n",
        "print(\"\\nCom rejeição (auto threshold):\", best_t)\n",
        "print(classification_report(va_targets, pred_rej, target_names=[idx_to_name[i] for i in range(4)]))\n",
        "\n",
        "onnx_path = \"/content/car_classifier.onnx\"\n",
        "dummy = torch.randn(1, 3, cfg.img_size, cfg.img_size).to(device)\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy,\n",
        "    onnx_path,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"logits\"],\n",
        "    dynamic_axes={\"input\": {0: \"batch\"}, \"logits\": {0: \"batch\"}},\n",
        "    opset_version=17\n",
        ")\n",
        "print(\"\\nONNX exportado:\", onnx_path)\n",
        "\n",
        "def bench_latency(model, device, n_warmup=20, n_iters=100):\n",
        "    model.eval()\n",
        "    x = torch.randn(1, 3, cfg.img_size, cfg.img_size).to(device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_warmup):\n",
        "            _ = model(x)\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "        t0 = time.time()\n",
        "        for _ in range(n_iters):\n",
        "            _ = model(x)\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "        dt = (time.time() - t0) / n_iters\n",
        "    print(f\"Latency médio: {dt*1000:.2f} ms | device={device} | batch=1 | iters={n_iters}\")\n",
        "\n",
        "bench_latency(model, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc2avxTP3v6o"
      },
      "source": [
        "## TTA + Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYxKb6k83ol0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_probs_tta_flip(model, loader):\n",
        "    \"\"\"\n",
        "    TTA simples: média das probabilidades\n",
        "      - original\n",
        "      - flip horizontal\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    probs_all, y_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "\n",
        "            logits1 = model(x)\n",
        "            p1 = torch.softmax(logits1, dim=1)\n",
        "\n",
        "            x_flip = torch.flip(x, dims=[3])  \n",
        "            logits2 = model(x_flip)\n",
        "            p2 = torch.softmax(logits2, dim=1)\n",
        "\n",
        "            p = 0.5 * (p1 + p2)\n",
        "\n",
        "            probs_all.append(p.cpu().numpy())\n",
        "            y_all.append(y.numpy())\n",
        "\n",
        "    return np.concatenate(probs_all, axis=0), np.concatenate(y_all, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws4BdnlD3rHT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "def apply_classwise_rejection(probs, thr_by_class, undefined_id=3):\n",
        "    \"\"\"\n",
        "    probs: [N,C]\n",
        "    thr_by_class: dict {class_id: thr}\n",
        "    regra:\n",
        "      pred = argmax\n",
        "      se conf(pred) < thr[pred] -> undefined\n",
        "    \"\"\"\n",
        "    conf = probs.max(axis=1)\n",
        "    pred = probs.argmax(axis=1)\n",
        "    pred_rej = pred.copy()\n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        c = int(pred[i])\n",
        "        if c == undefined_id:\n",
        "            continue\n",
        "        thr = thr_by_class.get(c, 0.5)\n",
        "        if conf[i] < thr:\n",
        "            pred_rej[i] = undefined_id\n",
        "\n",
        "    return pred, pred_rej, conf\n",
        "\n",
        "\n",
        "def search_thresholds_per_class(probs, y_true, thr_grid=None, undefined_id=3, class_ids=(0,1,2)):\n",
        "    \"\"\"\n",
        "    Busca thresholds por classe maximizando macro-F1 (com rejeição classwise).\n",
        "    Estratégia leve e efetiva:\n",
        "      - varre um threshold por vez mantendo os outros fixos\n",
        "      - repete por 2-3 rodadas\n",
        "    \"\"\"\n",
        "    if thr_grid is None:\n",
        "        thr_grid = np.linspace(0.30, 0.95, 14)\n",
        "\n",
        "    thr_by = {c: 0.6 for c in class_ids}\n",
        "\n",
        "    def score(thr_by_local):\n",
        "        _, pred_rej, _ = apply_classwise_rejection(probs, thr_by_local, undefined_id=undefined_id)\n",
        "        return f1_score(y_true, pred_rej, average=\"macro\")\n",
        "\n",
        "    best_score = score(thr_by)\n",
        "\n",
        "    for _round in range(3):\n",
        "        improved = False\n",
        "        for c in class_ids:\n",
        "            cur_best_t = thr_by[c]\n",
        "            cur_best_s = best_score\n",
        "\n",
        "            for t in thr_grid:\n",
        "                trial = dict(thr_by)\n",
        "                trial[c] = float(t)\n",
        "                s = score(trial)\n",
        "                if s > cur_best_s:\n",
        "                    cur_best_s = s\n",
        "                    cur_best_t = float(t)\n",
        "\n",
        "            if cur_best_s > best_score:\n",
        "                thr_by[c] = cur_best_t\n",
        "                best_score = cur_best_s\n",
        "                improved = True\n",
        "\n",
        "        if not improved:\n",
        "            break\n",
        "\n",
        "    return thr_by, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBB86rN93uFe",
        "outputId": "a7e5cc39-9779-4796-c9fc-fbfc07254714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== TTA (flip) | Sem rejeição ===\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "            BMW_3Series       0.40      0.62      0.48        13\n",
            "            BMW_5Series       0.46      0.60      0.52        10\n",
            "BMW_7Series_or_Fallback       0.50      0.77      0.61        13\n",
            "              undefined       0.74      0.53      0.62        60\n",
            "\n",
            "               accuracy                           0.58        96\n",
            "              macro avg       0.53      0.63      0.56        96\n",
            "           weighted avg       0.64      0.58      0.59        96\n",
            "\n",
            "\n",
            "Best thresholds por classe: {0: 0.8999999999999999, 1: 0.75, 2: 0.8999999999999999}\n",
            "Best macro-F1 (classwise rejection): 0.7028518356643356\n",
            "\n",
            "=== TTA (flip) | Com rejeição (threshold por classe) ===\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "            BMW_3Series       0.62      0.62      0.62        13\n",
            "            BMW_5Series       0.83      0.50      0.62        10\n",
            "BMW_7Series_or_Fallback       0.89      0.62      0.73        13\n",
            "              undefined       0.79      0.90      0.84        60\n",
            "\n",
            "               accuracy                           0.78        96\n",
            "              macro avg       0.78      0.66      0.70        96\n",
            "           weighted avg       0.79      0.78      0.77        96\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "va_probs_tta, va_targets = predict_probs_tta_flip(model, val_loader)\n",
        "\n",
        "print(\"\\n=== TTA (flip) | Sem rejeição ===\")\n",
        "pred = va_probs_tta.argmax(axis=1)\n",
        "print(classification_report(va_targets, pred, target_names=[idx_to_name[i] for i in range(4)]))\n",
        "\n",
        "thr_grid = np.linspace(0.35, 0.95, 13)\n",
        "thr_by_class, best_macro = search_thresholds_per_class(\n",
        "    va_probs_tta, va_targets, thr_grid=thr_grid, undefined_id=3, class_ids=(0,1,2)\n",
        ")\n",
        "\n",
        "print(\"\\nBest thresholds por classe:\", thr_by_class)\n",
        "print(\"Best macro-F1 (classwise rejection):\", best_macro)\n",
        "\n",
        "_, pred_rej, _ = apply_classwise_rejection(va_probs_tta, thr_by_class, undefined_id=3)\n",
        "\n",
        "print(\"\\n=== TTA (flip) | Com rejeição (threshold por classe) ===\")\n",
        "print(classification_report(va_targets, pred_rej, target_names=[idx_to_name[i] for i in range(4)]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22d79a7fc74f455f805fccda260a3940": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336a356efbf3407cbefd99faf8cf5cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d10b956675344dfb576d266e754f6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_962bbb76a03d480b851c5135b41780e7",
              "IPY_MODEL_62dc982ac5e744ea8e1f314476156ece",
              "IPY_MODEL_e3b3670bb85945babcbfe5efbc27debb"
            ],
            "layout": "IPY_MODEL_9d3193117c1a43d98010cfecebd23592"
          }
        },
        "62dc982ac5e744ea8e1f314476156ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de382acc7654fb29b09804ef193e5b2",
            "max": 86523256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8238ccb2f6544da29b6f4dc3e0fd3042",
            "value": 86523256
          }
        },
        "7470e3b52eef45f0a4ea5506a92e3461": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7de382acc7654fb29b09804ef193e5b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8238ccb2f6544da29b6f4dc3e0fd3042": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "962bbb76a03d480b851c5135b41780e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_336a356efbf3407cbefd99faf8cf5cb6",
            "placeholder": "​",
            "style": "IPY_MODEL_b871592528824d81b97473e1bddaffb9",
            "value": "model.safetensors: 100%"
          }
        },
        "9d3193117c1a43d98010cfecebd23592": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b871592528824d81b97473e1bddaffb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3b3670bb85945babcbfe5efbc27debb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d79a7fc74f455f805fccda260a3940",
            "placeholder": "​",
            "style": "IPY_MODEL_7470e3b52eef45f0a4ea5506a92e3461",
            "value": " 86.5M/86.5M [00:01&lt;00:00, 112MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
